{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import\n",
    "\n",
    "from sklearn import datasets;\n",
    "import pandas as pd;\n",
    "import numpy as np;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data and target\n",
    "\n",
    "diabetes_data = datasets.load_diabetes();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(diabetes_data.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(diabetes_data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diabetes = pd.DataFrame(diabetes_data.data)\n",
    "list(df_diabetes.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diabetes['target'] = pd.Series(diabetes_data.target)\n",
    "df_diabetes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_diabetes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(df_diabetes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data as matrix\n",
    "diabetes_mat = df_diabetes.as_matrix()\n",
    "\n",
    "#split the feature matrix and traget variable \n",
    "diabetes_X = diabetes_mat[:, 0:-1]\n",
    "diabetes_y = diabetes_mat[:,-1:]\n",
    "\n",
    "# Split the data into training/testing sets\n",
    "diabetes_X_train = diabetes_X[:-50]\n",
    "diabetes_X_test = diabetes_X[-50:]\n",
    "\n",
    "diabetes_y_train = diabetes_y[:-50]\n",
    "diabetes_y_test = diabetes_y[-50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.metrics import *\n",
    "import matplotlib.pyplot as plt\n",
    "#Linear Regression Example\n",
    "#This example uses the only the first feature of the diabetes dataset, in order to illustrate a two-dimensional plot of this regression technique. The straight line can be seen in the plot, showing how linear regression attempts to draw a straight line that will best minimize the residual sum of squares between the observed responses in the dataset, and the responses predicted by the linear approximation.\n",
    "\n",
    "#The coefficients, the residual sum of squares and the variance score are also calculated.\n",
    "#mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "diabetes_regr_model = regr.fit(diabetes_X_train, diabetes_y_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "diabetes_y_pred = diabetes_regr_model.predict(diabetes_X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The coefficients\n",
    "print('Coefficients: \\n', regr.coef_)\n",
    "\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\"\n",
    "      % mean_squared_error(diabetes_y_test, diabetes_y_pred))\n",
    "\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % r2_score(diabetes_y_test, diabetes_y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot outputs\n",
    "fig1 = plt.figure()\n",
    "plt.scatter(diabetes_y_test, diabetes_y_pred, color='black')\n",
    "plt.plot([diabetes_y_test.min(), diabetes_y_test.max()], [diabetes_y_test.min(), diabetes_y_test.max()], 'k--', lw=3, color='blue')\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.xlabel(\"Observed\")\n",
    "plt.ylabel(\"Predicted\")\n",
    "plt.show()\n",
    "fig1.savefig('regression_ind_test_diabetes.png')   # save the figure to file\n",
    "plt.close(fig1)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cross_val_predict returns an array of the same size as `y` where each entry\n",
    "### is a prediction obtained by cross validation:\n",
    "```\n",
    "from sklearn.model_selection import cross_val_predict,cross_val_score\n",
    "from sklearn import metrics\n",
    "\n",
    "scores = cross_val_score(regr, diabetes_data.data, diabetes_data.target, cv=10)\n",
    "diabetes_y_cv_pred = cross_val_predict(regr, diabetes_data.data, diabetes_data.target, cv=10)\n",
    "scores\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "diabetes_y_cv_test = diabetes_data.target\n",
    "import matplotlib.pyplot as plt\n",
    "fig2 = plt.figure();\n",
    "plt.scatter(diabetes_y_cv_test, diabetes_y_cv_pred, color='black')\n",
    "plt.plot([diabetes_y_cv_test.min(), diabetes_y_cv_test.max()], [diabetes_y_cv_test.min(), diabetes_y_cv_test.max()], 'k--', lw=3, color='blue')\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.xlabel(\"Observed\")\n",
    "plt.ylabel(\"Predicted\")\n",
    "plt.show()\n",
    "\n",
    "fig2.savefig('regression_cv_diabetes.png')\n",
    "plt.close(fig2)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import (RandomTreesEmbedding, RandomForestClassifier,\n",
    "                              GradientBoostingClassifier)\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import *\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=5000,n_features=500)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run classifier, using a model that is too regularized (C too low) to see\n",
    "# the impact on the results\n",
    "clf_svc = SVC(kernel='linear', C=0.01)\n",
    "y_pred_svc = clf_svc.fit(X_train, y_train).predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred_svc)\n",
    "np.set_printoptions(precision=2)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(2)\n",
    "plt.xticks(tick_marks, [\"0\",\"1\"], rotation=180)\n",
    "plt.yticks(tick_marks, [\"0\",\"1\"])\n",
    "thresh = cm.max() / 2.\n",
    "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "    plt.text(j, i, format(cm[i, j], 'd'),\n",
    "             horizontalalignment=\"center\",\n",
    "             color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create different classifiers. The logistic regression cannot do\n",
    "# multiclass out of the box.\n",
    "\n",
    "classifiers = {'L1 logistic': LogisticRegression(C=1.0, penalty='l1'),\n",
    "               'RDF': RandomForestClassifier(max_depth=3, n_estimators=100),\n",
    "               'GBC': GradientBoostingClassifier(n_estimators=100)\n",
    "               }\n",
    "\n",
    "n_classifiers = len(classifiers)\n",
    "\n",
    "for index, (name, classifier) in enumerate(classifiers.items()):\n",
    "    classifier.fit(X, y)\n",
    "\n",
    "    y_pred = classifier.predict(X)\n",
    "    f1 = f1_score(y,y_pred)\n",
    "    print(\"F1 Score for %s : %f \" % (name, f1))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc = GradientBoostingClassifier(n_estimators=100)\n",
    "gbc_model =  gbc.fit(X,y)\n",
    "rdf = RandomForestClassifier(n_estimators=100,max_depth=3)\n",
    "rdf_model = rdf.fit(X,y)\n",
    "logit = LogisticRegression(C=1.0, penalty='l1')\n",
    "logit_model = logit.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The gradient boosted model by itself\n",
    "y_pred_logit = logit_model.predict_proba(X_test)[:, 1]\n",
    "fpr_logit, tpr_logit, _ = roc_curve(y_test, y_pred_logit)\n",
    "\n",
    "# The gradient boosted model by itself\n",
    "y_pred_gbc = gbc_model.predict_proba(X_test)[:, 1]\n",
    "fpr_gbc, tpr_gbc, _ = roc_curve(y_test, y_pred_gbc)\n",
    "\n",
    "# The random forest model by itself\n",
    "y_pred_rf = rdf_model.predict_proba(X_test)[:, 1]\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test, y_pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig3 = plt.figure()\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_logit, tpr_logit, label='Logit')\n",
    "plt.plot(fpr_gbc, tpr_gbc, label='GBC')\n",
    "plt.plot(fpr_rf, tpr_rf, label='RDF')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig4 = plt.figure()\n",
    "plt.xlim(0, 0.4)\n",
    "plt.ylim(0.6, 1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_logit, tpr_logit, label='Logit')\n",
    "plt.plot(fpr_gbc, tpr_gbc, label='GBC')\n",
    "plt.plot(fpr_rf, tpr_rf, label='RDF')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Though the following import is not directly being used, it is required\n",
    "# for 3D projection to work\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import datasets\n",
    "\n",
    "np.random.seed(5)\n",
    "X, y = make_classification(n_samples=2000,n_features=5,n_classes=3,n_informative=3,n_clusters_per_class=1)\n",
    "\n",
    "estimators = [('k_means_3', KMeans(n_clusters=3))]\n",
    "\n",
    "fignum = 1\n",
    "titles = ['3 clusters']\n",
    "for name, est in estimators:\n",
    "    fig = plt.figure(fignum, figsize=(4, 3))\n",
    "    ax = Axes3D(fig, rect=[0, 0, .95, 1], elev=48, azim=134)\n",
    "    est.fit(X)\n",
    "    labels = est.labels_\n",
    "\n",
    "    ax.scatter(X[:, 3], X[:, 0], X[:, 2],\n",
    "               c=labels.astype(np.float), edgecolor='k')\n",
    "\n",
    "    ax.w_xaxis.set_ticklabels([])\n",
    "    ax.w_yaxis.set_ticklabels([])\n",
    "    ax.w_zaxis.set_ticklabels([])\n",
    "    ax.set_xlabel('0')\n",
    "    ax.set_ylabel('1')\n",
    "    ax.set_zlabel('2')\n",
    "    ax.set_title(titles[fignum - 1])\n",
    "    ax.dist = 12\n",
    "    fignum = fignum + 1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
