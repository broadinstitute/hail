--- src/main/scala/org/broadinstitute/hail/sparkextras/OrderedRDD.scala	2016-11-28 14:46:24.000000000 -0500
+++ src/main/scala/org/broadinstitute/hail/sparkextras/OrderedRDD.scala	2016-11-28 14:46:03.000000000 -0500
@@ -373,8 +373,7 @@
     new OrderedRDD[PK, K2, V2](rdd.mapPartitions(_.flatMap(f.tupled)), orderedPartitioner.mapMonotonic)
   }
 
-  import org.apache.spark.rdd.PartitionCoalescer
-  override def coalesce(maxPartitions: Int, shuffle: Boolean = false, partitionCoalescer: Option[PartitionCoalescer] = Option.empty)
+  override def coalesce(maxPartitions: Int, shuffle: Boolean = false)
     (implicit ord: Ordering[(K, V)] = null): RDD[(K, V)] = {
     require(maxPartitions > 0, "cannot coalesce to nPartitions <= 0")
     val n = rdd.partitions.length
