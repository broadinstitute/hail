# Hail Expression Language

Several Hail commands provide the ability to perform a broad array of computations based on data structures exposed to the user.

## Expressions and Operations

 - Conditionals: `if (p) a else b` -- The value of the conditional is the value of `a` or `b` depending on `p`.  If `p` is missing, the value of the conditional is missing.

 - Let: `let v1 = e1 and v2 = e2 and ... and vn = en in b` -- Bind variables `v1` through `vn` to result of evaluating the `ei`.  The value of the `let` is the value of `b`.  `v1` is visible in `e2` through `en`, etc.

 - Global comparisons: `a == b`, `a != b`

 - Boolean comparisons: `a || b`, `a && b`  Boolean comparisons short circuit.  If `a` is true, `a || b` is `true` without evaluating `b`.  If `a` is missing, `b` is evaluated and the comparison returns `true` if `b` is true, otherwise missing.

 - Boolean conversion
    - toInt: `b.toInt` -- returns `1` if `true`, `0` if `false`

 - Missingness:
     - isMissing: `isMissing(a)` -- returns true if `a` is missing
     - isDefined: `isDefined(a)` -- returns true if `a` is defined
     - orElse: `a.OrElse(x)` -- return `a` if `a` is defined, otherwise `x`.  `x` is only evaluated if `a` is NA.

 - Numerical comparisons: `<`, `<=`, `>`, `>=`

 - Numerical conversions:
     - toDouble: `i.toDouble`
     - toInt: `i.toInt`
     - toFloat: `i.toFloat`
     - toLong: `i.toLong`
     - str: `str(i)` -- returns `i` as a string

 - Numerical operations:
     - +, -, /, *, %: `a + b - c / d * e % f`.  `/` converts its arguments to Double, so `7 / 2` equals `3.5`
     - abs: `i.abs` -- returns the absolute value of `i`
     - signum: `i.signum` -- returns the sign of `i` (1, 0, or -1)
     - min: `i.min(j)` -- returns the minimum of `i` and `j`
     - max: `i.max(j)` -- returns the maximum of `i` and `j`
     - log(x[, b]) -- log of `x` base `b`.  If `b` is not given, the natural log of `x`.
     - log10(x) -- log of `x` base 10
     - exp(x) -- exponential of `x`
     - pow(b, e) -- `b` to the power `e`
     - sqrt(x) -- the square root of `x`

 - String operations:
     - 'regular expression pattern' ~ targetstring: Matches given `regular expression pattern` to `targetstring` and returns boolean.
     - apply: `str[index]` -- returns the character at `index`
     - length: `str.length` -- returns the length of the string
     - concatenate: `str1 + str2` -- returns the two strings joined start-to-end
     - split: `str.split(delimiter)` -- returns an array of strings, split on the given regular expression `delimiter`. If you need to    split on special characters, escape them with double backslash (\\\\). See Regular expression syntax: https://docs.oracle.com/javase/8/docs/api/java/util/regex/Pattern.html

 - String conversions:
    - toInt: `str.toInt`
    - toDouble: `str.toDouble`
    - toLong: `str.toLong`
    - toFloat: `str.toFloat`

 - Random Booleans and doubles:
     - pcoin(p) -- returns `true` with probability `p`. `p` should be between 0.0 and 1.0
     - runif(min, max) -- returns a random draw from a uniform distribution on \[`min`, `max`). `min` should be less than or equal to `max`
     - rnorm(mean, sd) -- returns a random draw from a normal distribution with mean `mean` and standard deviation `sd`. `sd` should be non-negative
     
 - Statistics
    - pnorm(x) -- Returns left-tail probability p for which p = Prob($Z$ < x) with $Z$ a standard normal random variable
    - qnorm(p) -- Returns left-quantile x for which p = Prob($Z$ < x) with $Z$ a standard normal random variable. `p` must satisfy `0 < p < 1`. Inverse of `pnorm`
    - pchisq1tail(x) -- Returns right-tail probability p for which p = Prob($Z^2$ > x) with $Z^2$ a chi-squared random variable with one degree of freedom. `x` must be positive
    - qchisq1tail(p) -- Returns right-quantile x for which p = Prob($Z^2$ > x) with $Z^2$ a chi-squared RV with one degree of freedom. `p` must satisfy `0 < p <= 1`. Inverse of `pchisq1tail`

 - Array Operations:
     - constructor: `[element1, element2, ...]` -- Create a new array from elements of the same type.
     - indexing: `arr[index]` -- get a value from the array, or NA if array or index is missing
     - slicing: `arr[start:end]` -- get a slice of the array (as an array).  The `start` is inclusive, the `end` is not.  For example, `[0,1,2,3,4][0:2]` returns `[0,1]`.  `[0,1,2,3,4,5][2:5]` returns `[2,3,4]`.
     - length / size: `arr.length` / `arr.size` -- returns the length of the array as an integer
     - isEmpty: `arr.isEmpty` -- returns true if the array has length 0
     - mkString: `arr.mkString(sep)` -- returns a string generated by joining elements sequentially, delimited by `sep`
     - toSet: `arr.toSet` -- returns a set of the same type (good if you need to call `.contains`, which is not available for arrays)
     - find: `arr.find(v => expr)` -- Returns the first non-missing element of `arr` for which `expr` is true.  If no element satisfies the predicate, `find` returns NA.
     - map: `arr.map(v => expr)` -- Returns a new array produced by applying `expr` to each element
     - flatMap: `arr.flatMap(v => expr)` -- valid only for `expr` of type Array. Returns a new array by mapping each element of `arr` and concatenating the resulting arrays
     - flatten: `arr.flatten()` -- Returns a new array by concatenating the elements of `arr`, which must be an array of arrays
     - filter: `arr.filter(v => expr)` -- Returns a new array subsetted to the elements where `expr` evaluated to true
     - exists: `arr.exists(v => expr)` -- Returns a boolean which is true if **any** element satisfies `expr`, false otherwise
     - forall: `arr.forall(v => expr)` -- Returns a boolean which is true if the array is empty, or `expr` evaluates to `true` for **every** element
     - sort: `arr.sort([ascending])` -- Returns a new array with the same elements in ascending order according to their value, which must be numeric or string. For descending order, use `arr.sort(false)`. Missing elements are always placed at the end.
     - sortBy: `arr.sortBy(v => expr[,ascending])` -- Returns a new array with the same elements in ascending order according to the value of `expr`, which must be numeric or string. For descending order, use `arr.sortBy(v => expr, false)`. Elements with missing `expr` values are always placed at the end.

 - Numeric Array Operations:
     - min: `arr.min` -- valid only for numeric arrays, returns the minimum value
     - max: `arr.max` -- valid only for numeric arrays, returns the minimum value
     - arithmetic: `+ - * /`
        - Array with scalar will apply the operation to each element of the array.  `[1, 2, 3] * 2` = `[2, 4, 6]`.
        - Array with Array will apply the operation positionally.  `[1, 2, 3] * [1, 0, -1]` = `[1, 0, -3]`.  _Fails if the dimension of the two arrays does not match._

 - Set Operations:
     - contains: `set.contains(elem)` -- returns true if the element is contained in the array, otherwise false
     - size: `set.size` -- returns the number of elements in the set as an integer
     - isEmpty: `set.isEmpty` -- returns true if the set contains 0 elements
     - equals: `set1 == set2` -- returns true if both sets contain the same elements
     - min: `set.min` -- valid only for numeric sets, returns the minimum value
     - max: `set.max` -- valid only for numeric sets, returns the minimum value
     - find: `set.find(v => expr)` -- Returns the first non-missing element of `set` for which `expr` is true.  If no element satisfies the predicate, `find` returns NA.
     - map: `set.map(v => expr)` -- Returns a new set produced by applying `expr` to each element
     - flatMap: `set.flatMap(v => expr)` -- valid only for `expr` of type Set. Returns a new set by mapping each element of `set` and taking the union of the resulting sets
     - flatten: `set.flatten()` -- Returns a new set by taking the union of elements of `set`, which must be a set of sets
     - filter: `set.filter(v => expr)` -- Returns a new set subsetted to the elements where `expr` evaluated to true
     - exists: `set.exists(v => expr)` -- Returns a boolean which is true if **any** element satisfies `expr`, false otherwise
     - forall: `set.forall(v => expr)` -- returns a boolean which is true if the set is empty, or `expr` evaluates to `true` for **every** element

 - Dict Operations:
     - select: `dict[key]` -- returns the value keyed by the string `key`.  An example might be `global.genedict["SCN2A"]`.
     - contains: `dict.contains(key)` -- returns true if `dict` has key `key`, false otherwise.
     - mapValues: `dict.mapValues(x => expr)` -- returns a new dict with a transformation of the values
     - size: `dict.size` -- returns the number of key/value pairs
     - isEmpty: `dict.isEmpty` -- returns true if there is at least one key/value pairs

 - Struct Operations:
     - constructor: `{key1: 1, key2: "Hello", key3: 0.99, ...}` -- Create a new struct from specified field names and values in the format shown.
     - select: `struct.field` -- returns the value of the given field of a struct.  For example, `va.info.AC` selects the struct `info` from the struct `va`, and then selects the array `AC` from the struct `info`.
     - index: `index(Array[Struct], fieldname)` -- returns a dictionary keyed by the string field `fieldname` of the given `struct`, referencing values that are structs with the remaining fields.

            For example, `global.gene_info` is the following `Array[Struct]`:

                 [{PLI: 0.998, genename: "gene1", hits_in_exac: 1},
                 {PLI: 0.0015, genename: "gene2", hits_in_exac: 10},
                 {PLI: 0.9045, genename: "gene3", hits_in_exac: 2}]

            We can index it by gene:

                global.gene_dict = index(global.gene_info, genename)

            Now the following equality is true:

                global.gene_dict["gene1"] == {PLI: 0.998, hits_in_exac: 1}

      - merge: `merge(struct1, struct2)` -- create a new struct with all fields in struct1 and struct2
      - select and drop: `select` / `drop` -- these take the format `select(struct, identifier1, identifier2, ...)`.  These methods return a subset of the struct.  One could, for example, remove the horrible `CSQ` from the info field of a vds with `annotatevariants expr -c 'va.info = drop(va.info, CSQ)`.  One can select a subset of fields from a table using `select(va.EIGEN, field1, field2, field3)`

  - Object constructors:

    - Variant: `Variant(chr, pos, ref, alt)`, where chr, ref, are `String`, and `pos` is Int, and `alt` is either a `String` or `Array[String]`
    - Variant: `Variant(str)`, where str is of the form `CHR:POS:REF:ALT` or `CHR:POS:REF:ALT1,ALT2...ALTN`
    - Locus: `Locus(chr, pos)`, where chr is a `String` and pos is an `Int`
    - Interval: `Interval(startLocus, endLocus)`, where startLocus and endLocus are loci
    
  - Apply methods:
    
    - range: `range(end)` or `range(start, end)`.  This function will produce an `Array[Int]`.  `range(3)` produces `[0, 1, 2]`.  `range(-2, 2)` produces `[-2, -1, 0, 1]`.

    - `gtj(i)` and `gtk(i)`.  Convert from genotype index (triangular numbers) to `j/k` pairs.

    - `gtIndex(j, k)`.  Convert from `j/k` pair to genotype index (triangular numbers).

**Note:**

 - All variables and values are case sensitive
 - Missingness propagates up.  If any element in an expression is missing, the expression will evaluate to missing.

## <a class="jumptarget" name="#aggregables"></a> Aggregables

Hail's expression language exposes a number of 'aggregables', special objects which allow users to specify computations across entire rows or columns of a dataset.  Aggregables allow a user to replicate nearly all the of the statistics generated in [`sampleqc`](commands.html#sampleqc) or [`variantqc`](commands.html#variantqc), as well as compute an unrestricted set of new metrics.

**Additional namespace of `gs`:**

Identifier | Description
:-: | ---
`v` | Variant
`va` | Variant annotations
`s` | Sample
`sa` | Sample annotations
`global` | Global annotations

**Additional namespace of `samples` in `annotateglobal`:**

Identifier | Description
:-: | ---
`sa` | Sample annotations
`global` | Global annotations

**Additional namespace of `variants` in `annotateglobal`:**

Identifier | Description
:-: | ---
`va` | Variant annotations
`global` | Global annotations

### Map and Filter

```
<aggregable>.map( <Any lambda expression> )
<aggregable>.filter( <Boolean lambda expression> )
```

These two generic helper functions allow the proceeding calculations to be totally general and modular.

`map` changes the type of an aggregable: `gs.map(g => g.gq)` takes the `Aggregable[Genotype]` "gs" and returns an `Aggregable[Int]`.

`filter` subsets an aggregable by excluding/including elements based on a lambda expression.  Note: does not change the type of an aggregable.  `gs.filter(g => g.isHet)` produces an aggregable where only heterozygous genotypes are considered.

### <a class="jumptarget" name="#aggregables_count"></a> Count

```
<aggregable>.count()
```

`count()` counts the number of included elements in this aggregable.

The result of `count` is a `Long` (integer).

**Examples:**

One can replicate `qc.nHet` for either samples or variants by counting:
```
annotatesamples expr -c 'sa.nHet = gs.filter(g => g.isHet).count()'
annotatevariants expr -c 'va.nHet = gs.filter(g => g.isHet).count()'
```

One can also compute more complicated counts.  Here we compute the number of non-ref cases and controls per variant (Assuming that `sa.pheno.isCase` is a boolean sample annotation)
```
annotatevariants expr -c 'va.caseCount = gs.filter(g => sa.pheno.isCase && g.isCalledNonRef).count(), va.controlCount = gs.filter(g => !(sa.pheno.isCase) && g.isCalledNonRef).count()'
```

Here we count the number of singleton non-ref LOFs and the number of homozygous alternate LOFs per sample, assuming that one has previously annotated variant consequence into `va.consequence`:
```
annotatevariants expr -c 'va.isSingleton = gs.filter(g => g.isCalledNonRef).count() == 1' \
annotatesamples expr -c 'sa.singletonLOFs = gs.filter(g => va.isSingleton && g.isCalledNonRef && va.consequence == "LOF").count(),
                    sa.homVarLOFs = gs.filter(g => g.isHomVar && va.consequence == "LOF").count()
```

This can also be used to calculate statistics from sample/variant annotations in `annotateglobal`:
```
annotatevariants expr -c 'va.isSingleton = gs.filter(g => g.isCalledNonRef).count() == 1'
annotatesamples expr -c 'sa.callrate = gs.fraction(g => g.isCalled)'
annotateglobal expr -c 'global.lowQualSamples = samples.filter(s => sa.callrate < 0.95).count(),
              global.totalNSingleton = variants.filter(v => va.isSingleton).count()'
```

### Fraction

```
<aggregable>.fraction( <Boolean lambda expression> )
```

`fraction` computes the ratio of the number of occurrences for which a boolean condition evaluates to `true`, divided the number of included elements in the aggregable.

The result of `fraction` is a `Double` (floating-point)

**Examples:**

One can replicate call rate, or calculate missingness:
```
filtervariants expr --keep -c 'gs.fraction(g => g.isCalled) > 0.90'
filtersamples expr --keep -c 'gs.fraction(g => g.isCalled) > 0.95'
```

One can also extend this thinking to compute the differential missingness at SNPs and indels:
```
annotatesamples expr -c 'sa.SNPmissingness = gs.filter(g => v.altAllele.isSNP).fraction(g => g.isNotCalled),
                    sa.indelmissingness = gs.filter(g => v.altAllele.isIndel).fraction(g => g.isNotCalled)
```

### Sum

`sum()` computes the sum of an `Aggregable[Numeric]`, or the position-wise sum of an `Aggregable[Array[Numeric]]`.  The result is a `Double` or `Long` in the first case, or `Array[Double]` or `Array[Long]` if the aggregable contains arrays.

**Examples:**

This aggregator function can be used to compute counts of each allele per variant.  The result will be an "R"-numbered array (one element per allele, including the reference):

```
annotatevariants expr -c 'va.AC = gs.map(g => g.oneHotAlleles(v)).sum()
```

Count the number of total LOF heterozygous calls in the dataset:

```
annotatevariants expr -c 'va.hets = gs.filter(g => g.isHet).count()' \
annotateglobal expr -c 'global.total_LOFs = 
    variants.filter(v => va.isLOF).map(v => va.hets).sum()'
```


### Stats

```
<numeric aggregable>.stats()
```

`stats()` computes six useful statistics about a numeric aggregable.

The result of `stats` is a struct:
```
Struct {
   mean: Double,
   stdev: Double,
   min: Double,
   max: Double,
   nNotMissing: Long,
   sum: Double
}
```

**Examples:**

One can replicate the calculations in `<va / sa>.qc.gqMean` and `<va / sa>.qc.gqStDev` with the command below.  After this command, `va.gqstats.mean` is equal to the result of running `variantqc` and querying `va.qc.gqMean`, and this equivalence holds for the other values.
```
annotatevariants expr -c 'va.gqstats = gs.map(g => g.gq).stats()'
annotatesamples expr -c 'sa.gqstats = g.map(g => g.gq).stats()'
```

One can use `stats` to compute statistics on annotations as well:
```
sampleqc
annotateglobal expr -c 'global.singletonStats = samples.map(s => sa.qc.nSingleton).stats()'
```

Compute gq/dp statistics stratified by genotype call:
```
annotatevariants expr -c '
    va.homrefGQ = gs.filter(g => g.isHomRef).map(g => g.gq).stats(),
    va.hetGQ = gs.filter(g => g.isHet).map(g => g.gq).stats(),
    va.homvarGQ = gs.filter(g => g.isHomVar).map(g => g.gq).stats(),
    va.homrefDP = gs.filter(g => g.isHomRef).map(g => g.dp).stats(),
    va.hetDP = gs.filter(g => g.isHet).map(g => g.dp).stats(),
    va.homvarDP = gs.filter(g => g.isHomVar).map(g => g.dp).stats()'
```

Compute statistics on number of singletons stratified by case/control:
```
 sampleqc
 annotateglobal expr -c 'global.caseSingletons = samples.filter(s => sa.fam.isCase).map(s => sa.qc.nSingleton).stats(),
     global.controlSingletons = samples.filter(s => !sa.fam.isCase).map(s => sa.qc.nSingleton).stats()'
```

### Counter

```
<aggregable>.counter()
```

This aggregator counts the number of occurrences of each element of an aggregable.  It produces an array of structs with the following schema:

```
Array [ 
  Struct {
    key: T, // element type of aggregator
    count: Long
  }
]
```

The resulting array is sorted by count in descending order (the most common element is first).

**Example:** compute the number of indels in each chromosome:

```
    annotateglobal expr -c 
      'global.chr_indels = variants
        .filter(v => v.altAllele.isIndel)
        .map(v => v.contig)
        .counter()'
```

### Hist

```
<numeric aggregable>.hist( start, end, bins )
```

This aggregator is used to compute frequency distributions of numeric parameters.  The start, end, and bins params are no-scope parameters, which means that while computations like `100 / 4` are acceptable, variable references like `global.nBins` are not.

The result of a `hist` invocation is a struct:

```
Struct {
    binEdges: Array[Double],
    binFrequencies: Array[Long],
    nLess: Long,
    nGreater: Long
}
```

Important properties:

 - Bin size is calculated from `(end - start) / bins`
 - (bins + 1) breakpoints are generated from the range `(start to end by binsize)`
 - `binEdges` stores an array of bin cutoffs.  Each bin is left-inclusive, right-exclusive except the last bin, which includes the maximum value.  This means that if there are N total bins, there will be N + 1 elements in binEdges.  For the invocation `hist(0, 3, 3)`, `binEdges` would be `[0, 1, 2, 3]` where the bins are `[0, 1)`, `[1, 2)`, `[2, 3]`.
 - `binFrequencies` stores the number of elements in the aggregable that fall in each bin.  It contains one element for each bin.
 - Elements greater than the max bin or less than the min bin will be tracked separately by `nLess` and `nGreater`

**Examples:**

Compute GQ-distributions per variant:

```
annotatevariants expr -c 'va.gqHist = gs.map(g => g.gq).hist(0, 100, 20)'
```

Or, extend the above to compute a global gq histogram:

```
annotatevariants expr -c 'va.gqHist = gs.map(g => g.gq).hist(0, 100, 20)'
annotateglobal expr -c 'global.gqHist = variants.map(v => va.gqHist.binFrequencies).sum()'
```

### Collect

```
<aggregable>.collect()
```

`collect()` is an aggregator that allows a set of elements of an aggregator to be collected into an `Array`.  For example, one can collect the list of non-ref sample IDs per variant with the following:

```
annotatevariants expr \
  -c 'va.hetSamples = gs.filter(g => g.isCalledNonRef)
                        .map(g => s.id)
                        .collect()'
```

The above example is updating the value of the `va.hetSamples` annotation. The value is calculated by transforming the array of genotypes, `gs`, in three steps.

  1. apply `filter(g => g.isCalledNonRef)` to keep only those genotypes which are non-reference
  2. apply `map(g => s.id)` to convert the each kept genotype to its corresponding sample id
  3. apply `collect()` to remove `NA`s and produce an `Array` of sample ids (which are `String`s)

### Call Stats

```
<aggregable>.callStats( <Variant lambda expression> )
```

`callStats` is an aggregator which operates on an `Aggregable[Genotype]` that computes four commonly-used metrics over a set of genotypes in a variant.  The resulting annotation is a struct:

```
Struct {
    AC: Array[Int],
    AF: Array[Double],
    AN: Int,
    GC: Array[Int]
}
```

In the above schema, the types mean the following:

 * `AC`: Allele count.  One element per allele **including reference**.  There are two elements for a biallelic variant, or 4 for a variant with three alternate alleles.
 * `AF`: Allele frequency.  One element per allele **including reference**.  Sums to 1.
 * `AN`: Allele number.  This is equal to the sum of AC, or 2 * the total number of called genotypes in the aggregable.
 * `GC`: Genotype count.  One element per possible genotype, including reference genotypes -- 3 for biallelic, 6 for triallelic, 10 for 3 alt alleles, and so on.  The sum of this array is the number of called genotypes in the aggregable.
 
**Example:** compute population-specific call statistics.  After the below command, `va.eur_stats.AC` will be the AC computed from individuals marked as "EUR".

```
annotatevariants expr -c "va.eur_stats = gs.filter(g => sa.pop == "EUR").callStats(g => v),
                          va.afr_stats = gs.filter(g => sa.pop == "AFR").callStats(g => v),
                          va.eas_stats = gs.filter(g => sa.pop == "EAS").callStats(g => v)"
```

### <a class="jumptarget" name="aggreg_hwe"></a> HardyWeinberg

```
<genotype aggregable>.hardyWeinberg()
```

`hardyWeinberg()` is an aggregator that computes a p-value computed from the [Hardy Weinberg Equilibrium (HWE) null model](LeveneHaldane.tex) on an aggregable of genotypes (gs). 

The result of `hardyWeinberg()` is a struct:

```
Struct {
    rExpectedHetFrequency: Double,
    pHWE: Double
}
```

In the above schema, `rExpectedHetFrequency` is the expected rHeterozygosity based on HWE and `pHWE` is the p-value.

**Examples:**

Add a new variant annotation that calculates HWE p-value by phenotype

```
annotatevariants expr -c 'va.hweCase = gs.filter(g => sa.pheno == "Case").hardyWeinberg(),
                          va.hweControl = gs.filter(g => sa.pheno == "Control").hardyWeinberg()'
```


### <a class="jumptarget" name="aggreg_infoscore"></a> InfoScore

```
<genotype aggregable>.infoScore()
```

`infoScore()` is an aggregator that computes an [IMPUTE info score](#infoscore_doc) on an aggregable of genotypes (gs). 

The result of `infoScore()` is a struct:

```
Struct {
    score: Double,
    nIncluded: Int
}
```

In the above schema, `score` is the IMPUTE info score produced, and `nIncluded` is the number of samples with non-missing dosages.

**Note:**
If the genotype data was not imported using the [`importbgen`](commands.html#importbgen) or [`importgen`](commands.html#importgen) commands, then the results for all variants will be `score = NA` and `nIncluded = 0`.

**Note:**
It only makes sense to compute info score for an `Aggregable[Genotype]` per variant.  While a per-sample info score will run complete, the result is meaningless. 

**Examples:**

Calculate the info score per variant and export the resulting annotations to a TSV file:

```
hail importgen -s /my/path/example.sample /my/path/example.gen 
    annotatevariants expr -c 'va.infoScore = gs.infoScore()' 
    exportvariants -c 'v, va.infoScore.score, va.infoScore.nIncluded' 
                   -o infoScores.tsv
```

Calculate group-specific info scores per variant:

```
hail importgen -s /my/path/example.sample /my/path/example.gen
    annotatesamples table -i phenotypes.tsv -r "sa.pheno"    
    annotatevariants expr -c 'va.infoScoreCase = gs.filter(g => sa.pheno.Pheno1 == "Case").infoScore()'
    annotatevariants expr -c 'va.infoScoreControl = gs.filter(g => sa.pheno.Pheno1 == "Control").infoScore()'    
```

### <a class="jumptarget" name="aggreg_ibc"></a> Inbreeding

```
<genotype aggregable>.inbreeding( <Double lambda expression> )
```

`inbreeding` is an aggregator that computes [inbreeding metrics](#ibc_doc) on an `Aggregable[Genotype]`.  It takes a lambda expression from `Genotype` to `Double` expression for the alt allele frequency as a required parameter.

The result of `inbreeding` is a struct:

```
Struct {
    fStat: Double,
    nTotal: Int,
    nCalled: Int,
    expectedHoms: Double,
    observedHoms: Int
}
```

In the above schema, `fStat` is the inbreeding coefficient produced, `nTotal` is the number of genotypes analyzed, `nCalled` is the number of genotypes with non-missing calls, `expectedHoms` is the expected number of homozygote calls, and `observedHoms` is the total number of homozygote calls observed.

**Note:** in the case of multiallelics, the allele frequency passed to this function should be the sum of all alternate allele frequencies.

**Examples:**

Calculate the inbreeding metrics per sample and export the resulting annotations to a TSV file:

```
hail read ... 
    variantqc
    annotatesamples expr -c 'sa.inbreeding = gs.inbreeding(g => va.qc.AF)' 
    exportsamples -c 'Sample = s, sa.inbreeding.*' -o ib_stats.tsv
```

Calculate the inbreeding metrics per variant and export these metrics to a TSV file:

```
hail read ...
    variantqc
    annotatevariants expr -c 'va.inbreeding = gs.inbreeding(g => va.qc.AF)'
    exportvariants -c 'Variant = v, va.inbreeding.*' -o ib_stats_variants.tsv

```

To obtain the same answer as [PLINK](https://www.cog-genomics.org/plink2), use the following series of commands:

```
read ... 
variantqc 
filtervariants expr --keep -c 'va.qc.AC > 1 && va.qc.AF >= 1e-8 && 
    va.qc.nCalled * 2 - va.qc.AC > 1 && va.qc.AF <= 1 - 1e-8 &&
    v.isAutosomal' 
annotatesamples expr -c 'sa.inbreeding = gs.inbreeding(g => va.qc.AF)'
```


## Filtering

Filtering requires an expression that evaluates to a boolean.

```
filtersamples expr --keep -c '"PT-1234" ~ s.id'
```


```
filtersamples expr --keep -c 'sa.qc.callRate > 0.99'
```

In the below expression, we will use a different cutoff for samples with European and non-European ancestry.  This can be done with an if/else statement.

```
filtersamples expr --keep -c 'if (sa.ancestry == "EUR") sa.qc.nSingleton < 100 else sa.qc.nSingleton < 200'
```

The below expression assumes a VDS was split from a VCF, and filters down to sites which were singletons on import.  `va.aIndex - 1` (NB: `va.aIndex` is the allele index, not the alternate allele index) indexes into the originally-multiallelic array `va.info.AC` with the original position of each variant.

```
filtervariants expr --keep -c 'if (va.info.AC[va.aIndex - 1]) == 1'
```

See documentation on [exporting to TSV](commands.html#ExportTSV) for more examples of what Hail's language can do.


## <a class="jumptarget" name="statsFunctions"></a> Statistical Functions

### <a class="jumptarget" name="fet"></a> Fisher's Exact Test

Hail's expression language exposes the `fet` function to calculate the p-value, odds ratio, and 95% confidence interval with Fisher's exact test for 2x2 tables. This implementation of FET is identical to the version implemented in [R](https://stat.ethz.ch/R-manual/R-devel/library/stats/html/fisher.test.html) with default parameters (two-sided, alpha = 0.05, null hypothesis that the odds ratio equals 1).

The `fet` function takes four non-negative arguments of type Int.
```
annotatevariants expr -c 'va.fet = fet(a, b, c, d)'
```

The function adds four annotations of type Double to the annotation root specified on the left-hand side of the equation:
 - `pValue`
 - `oddsRatio`
 - `ci95Lower`
 - `ci95Upper`

Note that the aggregator function `count()` creates annotation of type Long, which must be converted to Int as in the workflow below. Caution: the maximum value of an Int is 2147483647. Converting a Long of larger value to Int will corrupt the value.

**Example Workflow to Perform a Single-Variant Association Test Using FET:**
```
annotatesamples table -i /path/my/annotations.tsv -r "sa.pheno"
annotatevariants expr -c 'va.minorCase = gs.filter(g => sa.pheno.Pheno1 == "Case" && g.isHet).count() + 2 * gs.filter(g => sa.pheno.Pheno1 == "Case" && g.isHomVar).count()'
annotatevariants expr -c 'va.majorCase = gs.filter(g => sa.pheno.Pheno1 == "Case" && g.isHet).count() + 2 * gs.filter(g => sa.pheno.Pheno1 == "Case" && g.isHomRef).count()'
annotatevariants expr -c 'va.minorControl = gs.filter(g => sa.pheno.Pheno1 == "Control" && g.isHet).count() + 2 * gs.filter(g => sa.pheno.Pheno1 == "Control" && g.isHomVar).count()'
annotatevariants expr -c 'va.majorControl = gs.filter(g => sa.pheno.Pheno1 == "Control" && g.isHet).count() + 2 * gs.filter(g => sa.pheno.Pheno1 == "Control" && g.isHomRef).count()'
annotatevariants expr -c 'va.fet = fet(va.minorCase.toInt, va.majorCase.toInt, va.minorControl.toInt, va.majorControl.toInt)'
filtervariants expr --keep -c 'va.fet.pValue < 1e-4'
exportvariants -o /path/my/results.tsv -c 'v, va.minorCase, va.majorCase, va.minorControl, va.majorControl, va.fet.pValue, va.fet.oddsRatio, va.fet.ci95Lower, va.fet.ci95Upper'
```


### <a class="jumptarget" name="infoscore_doc"></a> IMPUTE Info Score (Dosage Data)

The `infoScore` aggregator can be used to calculate the IMPUTE info score from a [genotype aggregable](#aggreg_infoscore). 

**Example:**

```
annotatevariants expr -c 'va.infoScore = gs.infoScore()'
```

We implemented the IMPUTE info measure as described in the [supplementary information from Marchini & Howie. Genotype imputation for genome-wide association studies. Nature Reviews Genetics (2010)](http://www.nature.com/nrg/journal/v11/n7/extref/nrg2796-s3.pdf).

To calculate the info score $I_{A}$ for one SNP:

$$
I_{A} = 
\begin{cases}
1 - \frac{\sum_{i=1}^{N}(f_{i} - e_{i}^2)}{2N\hat{\theta}(1 - \hat{\theta})} & \text{when } \hat{\theta} \in (0, 1) \\
1 & \text{when } \hat{\theta} = 0, \hat{\theta} = 1\\
\end{cases}
$$

 - $N$ is the number of samples with imputed genotype probabilities [$p_{ik} = P(G_{i} = k)$ where $k \in \{0, 1, 2\}$]
 - $e_{i} = p_{i1} + 2p_{i2}$ is the expected genotype per sample
 - $f_{i} = p_{i1} + 4p_{i2}$
 - $\hat{\theta} = \frac{\sum_{i=1}^{N}e_{i}}{2N}$ is the MLE for the population minor allele frequency

Hail will not generate identical results as [QCTOOL](http://www.well.ox.ac.uk/~gav/qctool/#overview) for the following reasons:
 
 - The floating point number Hail stores for each dosage is slightly different than the original data due to rounding and normalization of probabilities.
 - Hail automatically removes dosages that [do not meet certain requirements](commands.html#dosagefilters) on data import with [`importgen`](commands.html#importgen) and [`importbgen`](commands.html#importbgen).
 - Hail does not use the population frequency to impute dosages when a dosage has been set to missing.
 - **Hail calculates the same statistic for sex chromosomes as autosomes while QCTOOL incorporates sex information**

**Warning!!! The info score Hail reports will be extremely different from qctool when a SNP has a high missing rate.**

### <a class="jumptarget" name="ibc_doc"></a> Inbreeding Coefficient

The `inbreeding` aggregator can be used to calculate the Inbreeding Coefficient from a [genotype aggregable](#aggreg_ibc).
This is equivalent to the [`--het` method in PLINK](https://www.cog-genomics.org/plink2/basic_stats#ibc).

The Inbreeding Coefficient (F) is computed as follows:

2. For each variant and sample with a non-missing genotype call, `E`, the expected number of homozygotes (computed from user-defined expression for minor allele frequency), is computed as `1.0 - (2.0*maf*(1.0-maf))`
3. For each variant and sample with a non-missing genotype call, `O`, the observed number of homozygotes, is computed as `0 = heterozygote; 1 = homozygote`
4. For each variant and sample with a non-missing genotype call, `N` is incremented by 1
5. For each sample, `E`, `O`, and `N` are combined across variants
6. `F` is calculated by `(O - E) / (N - E)`
